"""RAG (Retrieval-Augmented Generation) service."""
import os
from typing import List, Dict, Optional
from backend.core.config import settings
from backend.core.document_processor import pdf_to_docs, chunk_text
from backend.services.ai_service import ai_service
from backend.models.vector_store import vector_store
from backend.core.exceptions import AIServiceError, VectorStoreError


class RAGService:
    """Service for RAG operations: indexing and querying."""
    
    def __init__(self):
        """Initialize RAG service."""
        self.chunks: List[Dict] = []
        self.initialized = False
    
    def _find_docs_folder(self) -> str:
        """Th·ª≠ t√¨m th∆∞ m·ª•c docs ·ªü nhi·ªÅu v·ªã tr√≠ kh√°c nhau."""
        candidates = [
            settings.docs_folder,  # T·ª´ config
            os.path.join(os.getcwd(), "docs"), # T·∫°i th∆∞ m·ª•c ch·∫°y l·ªánh
            os.path.join(os.path.dirname(__file__), "../../docs"), # Relative t·ª´ file n√†y
            "docs", # ƒê∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi ƒë∆°n gi·∫£n
            "/tmp/docs" # Tr∆∞·ªùng h·ª£p deploy serverless
        ]
        
        for path in candidates:
            if path and os.path.exists(path) and os.path.isdir(path):
                print(f"‚úÖ ƒê√£ t√¨m th·∫•y th∆∞ m·ª•c docs t·∫°i: {path}")
                return path
        
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c docs. ƒê√£ th·ª≠: {candidates}")
        return settings.docs_folder

    def _load_documents(self) -> None:
        """Load and process documents."""
        docs_folder = self._find_docs_folder()
        
        all_docs = []
        
        # Load study document
        study_file_path = os.path.join(docs_folder, settings.study_file)
        
        if os.path.exists(study_file_path):
            print(f"üìï ƒêang ƒë·ªçc file: {study_file_path}")
            try:
                with open(study_file_path, "rb") as f:
                    file_content = f.read()
                    extracted_docs = pdf_to_docs(file_content, settings.study_file)
                    
                    if not extracted_docs:
                        print("‚ö†Ô∏è C·∫¢NH B√ÅO: File PDF ƒë∆∞·ª£c m·ªü nh∆∞ng kh√¥ng ƒë·ªçc ƒë∆∞·ª£c vƒÉn b·∫£n n√†o. C√≥ th·ªÉ ƒë√¢y l√† file scan (·∫£nh)?")
                    else:
                        print(f"‚úÖ ƒê√£ tr√≠ch xu·∫•t ƒë∆∞·ª£c {len(extracted_docs)} trang vƒÉn b·∫£n.")
                        
                    all_docs.extend(extracted_docs)
            except Exception as e:
                print(f"‚ùå L·ªói khi ƒë·ªçc file PDF: {e}")
        else:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file gi√°o tr√¨nh t·∫°i: {study_file_path}")
            # List c√°c file trong th∆∞ m·ª•c ƒë·ªÉ debug
            if os.path.exists(docs_folder):
                print(f"üìÇ C√°c file c√≥ trong {docs_folder}: {os.listdir(docs_folder)}")
        
        if not all_docs:
            print("‚ùå Kh√¥ng c√≥ t√†i li·ªáu n√†o ƒë∆∞·ª£c n·∫°p. Chatbot s·∫Ω kh√¥ng c√≥ ki·∫øn th·ª©c.")
            return
        
        # Create chunks
        self.chunks = []
        for doc in all_docs:
            chunks_text = chunk_text(doc["text"])
            for idx, chunk_text_str in enumerate(chunks_text):
                chunk = {
                    "text": chunk_text_str,
                    "source": doc["source"],
                    "chunk_id": idx,
                    "type": doc["type"]
                }
                if "page" in doc:
                    chunk["page"] = doc["page"]
                self.chunks.append(chunk)
        
        print(f"üìö ƒê√£ t·∫°o {len(self.chunks)} ƒëo·∫°n d·ªØ li·ªáu (chunks) t·ª´ {len(all_docs)} trang t√†i li·ªáu")
    
    def _build_index(self) -> None:
        """Build FAISS index from chunks."""
        if not self.chunks:
            print("‚ö†Ô∏è Kh√¥ng c√≥ chunks ƒë·ªÉ ƒë√°nh ch·ªâ m·ª•c (Index)")
            return
        
        try:
            # Generate embeddings
            texts = [c["text"] for c in self.chunks]
            print(f"üîÑ ƒêang t·∫°o embedding cho {len(texts)} ƒëo·∫°n vƒÉn b·∫£n...")
            embeddings = ai_service.embed_texts(texts)
            
            if len(embeddings) == 0:
                print("‚ùå L·ªói: API kh√¥ng tr·∫£ v·ªÅ embedding n√†o.")
                return

            print(f"‚úÖ ƒê√£ t·∫°o xong {len(embeddings)} embeddings")
            
            # Build index
            print("üîÑ ƒêang x√¢y d·ª±ng FAISS index...")
            vector_store.build_index(embeddings)
            print("‚úÖ FAISS index x√¢y d·ª±ng th√†nh c√¥ng")
            
            self.initialized = True
        except Exception as e:
            print(f"‚ùå L·ªói nghi√™m tr·ªçng khi x√¢y d·ª±ng index: {e}")
            raise
    
    def ask_question(self, question: str, top_k: Optional[int] = None) -> Dict:
        """Answer a question using RAG."""
        if not self.initialized:
            # Th·ª≠ kh·ªüi t·∫°o l·∫°i n·∫øu ch∆∞a c√≥
            print("‚ö†Ô∏è RAG ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o, ƒëang th·ª≠ kh·ªüi t·∫°o l·∫°i...")
            self.initialize()
            if not self.initialized:
                return {
                    "answer": "H·ªá th·ªëng ƒëang g·∫∑p s·ª± c·ªë khi ƒë·ªçc t√†i li·ªáu. Vui l√≤ng ki·ªÉm tra logs server.",
                    "sources": []
                }
        
        question = question.strip()
        if not question:
            raise ValueError("Question cannot be empty")
        
        if top_k is None:
            top_k = settings.top_k
        
        # Get query embedding
        query_vector = ai_service.embed_texts([question])
        
        # Search for similar chunks
        indices, scores = vector_store.search(query_vector, top_k)
        
        # Filter valid indices
        valid_indices = [i for i in indices if 0 <= i < len(self.chunks)]
        contexts = [self.chunks[i] for i in valid_indices]
        
        print(f"üîç T√¨m th·∫•y {len(contexts)} ƒëo·∫°n li√™n quan cho c√¢u h·ªèi: '{question}'")
        
        print("====== KI·ªÇM TRA N·ªòI DUNG CHUNKS ======")
        for i, ctx in enumerate(contexts[:3]): # Ch·ªâ in 3 ƒëo·∫°n ƒë·∫ßu
            print(f"Chunk {i+1}: {ctx['text'][:200]}...") # In 200 k√Ω t·ª± ƒë·∫ßu
            print("------------------------------------")
        # Generate answer
        answer = ai_service.generate_response(question, contexts)
        
        # Prepare response
        unique_sources = sorted(set([c["source"] for c in contexts]))
        unique_pages = sorted(set([c.get("page") for c in contexts if "page" in c]))
        
        return {
            "answer": answer,
            "sources": [
                {
                    "type": c.get("type", "unknown"),
                    "source": c["source"],
                    "page": c.get("page"),
                    "text": c["text"][:200],
                }
                for c in contexts
            ],
            "documents_used": unique_sources,
            "pages_used": unique_pages,
        }

    def initialize(self) -> None:
        """Initialize RAG service by loading documents and building index."""
        print("üöÄ ƒêang kh·ªüi ƒë·ªông RAG service...")
        self._load_documents()
        self._build_index()
        if self.initialized:
            print("‚ú® RAG service ƒë√£ s·∫µn s√†ng!")
        else:
            print("üíÄ RAG service kh·ªüi ƒë·ªông th·∫•t b·∫°i.")


# Global RAG service instance
rag_service = RAGService()